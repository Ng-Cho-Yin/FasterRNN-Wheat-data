{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from IPython.display import Image\nImage('../input/global-wheat-detection/train/00333207f.jpg',width=600)","metadata":{"execution":{"iopub.status.busy":"2022-07-06T19:12:05.901655Z","iopub.execute_input":"2022-07-06T19:12:05.902181Z","iopub.status.idle":"2022-07-06T19:12:05.975500Z","shell.execute_reply.started":"2022-07-06T19:12:05.902085Z","shell.execute_reply":"2022-07-06T19:12:05.974657Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\n# Set default figure size\nplt.rcParams['figure.figsize'] = (10.0, 10.0)\nimport cv2\nimport pandas as pd\nimport os\nimport ast\nimport numpy as np\nimport torch","metadata":{"execution":{"iopub.status.busy":"2022-07-06T19:12:09.670663Z","iopub.execute_input":"2022-07-06T19:12:09.671042Z","iopub.status.idle":"2022-07-06T19:12:11.517450Z","shell.execute_reply.started":"2022-07-06T19:12:09.671008Z","shell.execute_reply":"2022-07-06T19:12:11.516455Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"pd.read_csv('../input/global-wheat-detection/train.csv')","metadata":{"execution":{"iopub.status.busy":"2022-07-06T19:12:13.512797Z","iopub.execute_input":"2022-07-06T19:12:13.513298Z","iopub.status.idle":"2022-07-06T19:12:13.776571Z","shell.execute_reply.started":"2022-07-06T19:12:13.513267Z","shell.execute_reply":"2022-07-06T19:12:13.775653Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#image_loader_function\n#load from train.csv\ntrain_dir = '../input/global-wheat-detection/train'\ndef image_loader(image_id):\n    path = os.path.join(train_dir,image_id+'.jpg')\n    image = cv2.imread(path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = image/255 # Scale to [0,1]\n    return image\n\n","metadata":{"execution":{"iopub.status.busy":"2022-07-06T19:12:16.306750Z","iopub.execute_input":"2022-07-06T19:12:16.307116Z","iopub.status.idle":"2022-07-06T19:12:16.313226Z","shell.execute_reply.started":"2022-07-06T19:12:16.307084Z","shell.execute_reply":"2022-07-06T19:12:16.312077Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"print(image_loader('5e0747034').shape)\nimage_loader('5e0747034')","metadata":{"execution":{"iopub.status.busy":"2022-07-06T18:30:30.739821Z","iopub.execute_input":"2022-07-06T18:30:30.740218Z","iopub.status.idle":"2022-07-06T18:30:30.806976Z","shell.execute_reply.started":"2022-07-06T18:30:30.740185Z","shell.execute_reply":"2022-07-06T18:30:30.805978Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"print(torch.from_numpy(image_loader('b6ab77fd7')).permute(2,0,1).shape)\ntorch.from_numpy(image_loader('b6ab77fd7')).permute(2,0,1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.from_numpy(image_loader('b6ab77fd7')).permute(2,0,1)[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(image_loader('b6ab77fd7'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/global-wheat-detection/train.csv')\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2022-07-06T19:12:22.456002Z","iopub.execute_input":"2022-07-06T19:12:22.457495Z","iopub.status.idle":"2022-07-06T19:12:22.625633Z","shell.execute_reply.started":"2022-07-06T19:12:22.457447Z","shell.execute_reply":"2022-07-06T19:12:22.624689Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_df['bbox'] = train_df['bbox'].apply(ast.literal_eval)\nxywh_df = pd.DataFrame(train_df['bbox'].to_list(), columns=[\"x\", \"y\", \"w\", \"h\"])\nx2_df = pd.DataFrame(xywh_df.x+xywh_df.w,columns=['x2'])\ny2_df = pd.DataFrame(xywh_df.y+xywh_df.h,columns=['y2'])\ntrain_df = train_df.join([xywh_df, x2_df, y2_df])","metadata":{"execution":{"iopub.status.busy":"2022-07-06T19:12:25.279074Z","iopub.execute_input":"2022-07-06T19:12:25.279731Z","iopub.status.idle":"2022-07-06T19:12:27.282695Z","shell.execute_reply.started":"2022-07-06T19:12:25.279693Z","shell.execute_reply":"2022-07-06T19:12:27.281744Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_df","metadata":{"execution":{"iopub.status.busy":"2022-07-06T19:12:29.374556Z","iopub.execute_input":"2022-07-06T19:12:29.375157Z","iopub.status.idle":"2022-07-06T19:12:29.404062Z","shell.execute_reply.started":"2022-07-06T19:12:29.375118Z","shell.execute_reply":"2022-07-06T19:12:29.402889Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_df[train_df['image_id']=='b6ab77fd7'][['x', 'y', 'x2', 'y2']].values.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#draw boxes on img\ndef bboxes_on_imgs(image,boxes,color=(255,0,0),acc='1'):\n    for box in boxes:\n        cv2.rectangle(image,\n                      (int(box[0]),int(box[1])),\n                       (int(box[2]),int(box[3])),\n                       color,3)\n        cv2.putText(image, acc, (int(box[0]),int(box[1])), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n    return image","metadata":{"execution":{"iopub.status.busy":"2022-07-06T19:12:32.863525Z","iopub.execute_input":"2022-07-06T19:12:32.863888Z","iopub.status.idle":"2022-07-06T19:12:32.870601Z","shell.execute_reply.started":"2022-07-06T19:12:32.863855Z","shell.execute_reply":"2022-07-06T19:12:32.869652Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Sample a random training instance and draw the labelled bounding boxes\nsample_image_id =  train_df.image_id.sample().item()\n#sample_image_id = 'b6ab77fd7'\nsample_bboxes = train_df[train_df['image_id']==sample_image_id][['x','y','x2','y2']]\n\n\nprint('image_id:',sample_image_id)\nprint(len(sample_bboxes.to_numpy()),'bboxes')\nplt.imshow(bboxes_on_imgs(image_loader(sample_image_id),sample_bboxes.to_numpy()))","metadata":{"execution":{"iopub.status.busy":"2022-07-06T19:12:35.132807Z","iopub.execute_input":"2022-07-06T19:12:35.133266Z","iopub.status.idle":"2022-07-06T19:12:35.908260Z","shell.execute_reply.started":"2022-07-06T19:12:35.133227Z","shell.execute_reply":"2022-07-06T19:12:35.906919Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"#  **Load Pretained Model** (Torch)","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torchvision.models.detection import fasterrcnn_resnet50_fpn\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\nfrom torch.utils.data import DataLoader, Dataset","metadata":{"execution":{"iopub.status.busy":"2022-07-06T19:12:41.258977Z","iopub.execute_input":"2022-07-06T19:12:41.260022Z","iopub.status.idle":"2022-07-06T19:12:41.484506Z","shell.execute_reply.started":"2022-07-06T19:12:41.259974Z","shell.execute_reply":"2022-07-06T19:12:41.483523Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Download a pre-trained bounding box detector\nmodel = fasterrcnn_resnet50_fpn(pretrained=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-06T19:12:45.436381Z","iopub.execute_input":"2022-07-06T19:12:45.437219Z","iopub.status.idle":"2022-07-06T19:12:54.736503Z","shell.execute_reply.started":"2022-07-06T19:12:45.437185Z","shell.execute_reply":"2022-07-06T19:12:54.735534Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2022-07-06T19:12:56.290772Z","iopub.execute_input":"2022-07-06T19:12:56.294170Z","iopub.status.idle":"2022-07-06T19:12:56.317521Z","shell.execute_reply.started":"2022-07-06T19:12:56.294113Z","shell.execute_reply":"2022-07-06T19:12:56.313918Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"model.roi_heads","metadata":{"execution":{"iopub.status.busy":"2022-07-06T19:13:01.337494Z","iopub.execute_input":"2022-07-06T19:13:01.337851Z","iopub.status.idle":"2022-07-06T19:13:01.346995Z","shell.execute_reply.started":"2022-07-06T19:13:01.337820Z","shell.execute_reply":"2022-07-06T19:13:01.345912Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Replace the pre-trained bounding box detector head with\n# a new one that predicts our desired 2 classes {BACKGROUND, WHEAT}\nin_features = model.roi_heads.box_predictor.cls_score.in_features\nmodel.roi_heads.box_predictor = FastRCNNPredictor(in_channels=in_features, num_classes=2)\n\n# Verify the model architecture\nmodel.roi_heads","metadata":{"execution":{"iopub.status.busy":"2022-07-06T19:13:03.929390Z","iopub.execute_input":"2022-07-06T19:13:03.929740Z","iopub.status.idle":"2022-07-06T19:13:03.938109Z","shell.execute_reply.started":"2022-07-06T19:13:03.929709Z","shell.execute_reply":"2022-07-06T19:13:03.937135Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')","metadata":{"execution":{"iopub.status.busy":"2022-07-06T19:13:07.384969Z","iopub.execute_input":"2022-07-06T19:13:07.385626Z","iopub.status.idle":"2022-07-06T19:13:07.456207Z","shell.execute_reply.started":"2022-07-06T19:13:07.385588Z","shell.execute_reply":"2022-07-06T19:13:07.455111Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2022-07-06T19:13:09.484651Z","iopub.execute_input":"2022-07-06T19:13:09.485030Z","iopub.status.idle":"2022-07-06T19:13:10.212632Z","shell.execute_reply.started":"2022-07-06T19:13:09.484996Z","shell.execute_reply":"2022-07-06T19:13:10.211470Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"unique_img_ids = train_df['image_id'].unique()\nn_val = int(len(unique_img_ids)*0.2)\nval_ids=unique_img_ids[-n_val:]\ntrain_ids=unique_img_ids[:-n_val]\n\nval_df = train_df[train_df['image_id'].isin(val_ids)]\ntrain_df = train_df[train_df['image_id'].isin(train_ids)]\n\nprint('validation sample:',len(val_ids))\nprint('training sample:',len(train_ids))","metadata":{"execution":{"iopub.status.busy":"2022-07-06T19:13:14.807508Z","iopub.execute_input":"2022-07-06T19:13:14.808265Z","iopub.status.idle":"2022-07-06T19:13:14.869593Z","shell.execute_reply.started":"2022-07-06T19:13:14.808227Z","shell.execute_reply":"2022-07-06T19:13:14.868497Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Inherit from pytorch Dataset for convenience\n\nclass WheatDataset(Dataset):\n    def __init__(self, dataframe):\n        super().__init__()\n        self.df = dataframe\n        self.image_ids = dataframe['image_id'].unique()\n        \n    def __len__(self) -> int:\n        return len(self.image_ids)\n    \n    def __getitem__(self, index: int):\n        image_id = self.image_ids[index]\n        image = image_loader(image_id).astype(np.float32)\n        # Convert the shape from [h,w,c] to [c,h,w] as expected by pytorch\n        image = torch.from_numpy(image).permute(2,0,1)\n        boxes = torch.as_tensor(self.df[self.df['image_id'] == image_id][['x', 'y', 'x2', 'y2']].values, dtype=torch.float32)\n        n_boxes = boxes.shape[0]\n        # there is only one foreground class, WHEAT\n        labels = torch.ones(n_boxes, dtype=torch.int64)\n        target = {}\n        target['boxes'] = boxes\n        target['labels'] = labels\n        \n        return image, target","metadata":{"execution":{"iopub.status.busy":"2022-07-06T19:13:17.319097Z","iopub.execute_input":"2022-07-06T19:13:17.321486Z","iopub.status.idle":"2022-07-06T19:13:17.330647Z","shell.execute_reply.started":"2022-07-06T19:13:17.321451Z","shell.execute_reply":"2022-07-06T19:13:17.329776Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"torch.ones((10), dtype=torch.int64)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = torch.randn(1, 2, 3)\nx","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.randn(3, 2, 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x.permute(2,1,0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create Pytorch DataLoaders for training and validation datasets\n\ntrain_dataset = WheatDataset(train_df)\nvalid_dataset = WheatDataset(val_df)\n\n# A function to bring images with different\n# number of bounding boxes into the same batch\ndef collate_fn(batch):\n    return tuple(zip(*batch))\n\nis_training_on_cpu = device == torch.device('cpu')\nbatch_size = 4 if is_training_on_cpu else 16\n\ntrain_data_loader = DataLoader(\n    train_dataset,\n    batch_size=batch_size,\n    shuffle=True,\n    num_workers=4,\n    collate_fn=collate_fn\n)\n\nvalid_data_loader = DataLoader(\n    valid_dataset,\n    batch_size=batch_size,\n    shuffle=False,\n    num_workers=4,\n    collate_fn=collate_fn\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-06T19:13:21.796410Z","iopub.execute_input":"2022-07-06T19:13:21.797462Z","iopub.status.idle":"2022-07-06T19:13:21.822030Z","shell.execute_reply.started":"2022-07-06T19:13:21.797416Z","shell.execute_reply":"2022-07-06T19:13:21.820685Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"Explaination for collate_fn():\nhttps://python.plainenglish.io/understanding-collate-fn-in-pytorch-f9d1742647d3","metadata":{}},{"cell_type":"code","source":"# Test the data loader\nbatch_of_images, batch_of_targets = next(iter(train_data_loader))\n\nsample_boxes = batch_of_targets[0]['boxes'].numpy().astype(np.int32)\nsample_image = batch_of_images[0].permute(1,2,0).numpy() # convert back from pytorch format\n\nplt.imshow(bboxes_on_imgs(sample_image,sample_boxes,color=(0,200,200)))","metadata":{"execution":{"iopub.status.busy":"2022-07-06T19:13:25.802872Z","iopub.execute_input":"2022-07-06T19:13:25.803566Z","iopub.status.idle":"2022-07-06T19:13:31.921883Z","shell.execute_reply.started":"2022-07-06T19:13:25.803528Z","shell.execute_reply":"2022-07-06T19:13:31.920922Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# Training the model","metadata":{}},{"cell_type":"code","source":"# optimiser: stochastic gradient descent\noptimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9)\n\n#eash number of epochs\nnum_epochs = 1\n\n# Prepare the pretained model\nmodel = model.to(device)\nmodel.train()\n\nprint('-------------------------------Pretrained FasterRCNN ready-------------------------------')","metadata":{"execution":{"iopub.status.busy":"2022-07-06T19:14:15.191152Z","iopub.execute_input":"2022-07-06T19:14:15.191534Z","iopub.status.idle":"2022-07-06T19:14:17.867249Z","shell.execute_reply.started":"2022-07-06T19:14:15.191501Z","shell.execute_reply":"2022-07-06T19:14:17.866174Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def move_batch_to_device(images, targets):\n    images = list(image.to(device) for image in images)\n    targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n    return images, targets","metadata":{"execution":{"iopub.status.busy":"2022-07-06T19:15:07.986156Z","iopub.execute_input":"2022-07-06T19:15:07.987177Z","iopub.status.idle":"2022-07-06T19:15:07.992743Z","shell.execute_reply.started":"2022-07-06T19:15:07.987126Z","shell.execute_reply":"2022-07-06T19:15:07.991838Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"for epoch in range(num_epochs):\n    print('Epoch {}/{}'.format(epoch+1,num_epochs))\n    average_loss = 0\n    for batch_id, (images, targets) in enumerate(train_data_loader):\n        # Prepare the batch data\n        images, targets = move_batch_to_device(images, targets)\n\n        # Calculate losses\n        loss_dict = model(images, targets)\n        batch_loss = sum(loss for loss in loss_dict.values()) / len(loss_dict)\n        \n        # Refresh accumulated optimiser state and minimise losses\n        optimizer.zero_grad()\n        batch_loss.backward()\n        optimizer.step()\n        \n        # Record stats\n        loss_value = batch_loss.item()\n        average_loss = average_loss + (loss_value - average_loss) / (batch_id + 1)\n        print(\"Mini-batch: %i/%i Loss: %.4f\" % ( batch_id + 1, len(train_data_loader), average_loss), end='\\r')\n        if batch_id % 100 == 0:\n            print(\"Mini-batch: %i/%i Loss: %.4f\" % ( batch_id + 1, len(train_data_loader), average_loss))","metadata":{"execution":{"iopub.status.busy":"2022-07-06T19:15:10.374342Z","iopub.execute_input":"2022-07-06T19:15:10.374697Z","iopub.status.idle":"2022-07-06T19:20:53.984619Z","shell.execute_reply.started":"2022-07-06T19:15:10.374666Z","shell.execute_reply":"2022-07-06T19:20:53.983160Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"model.eval()\ncpu_device = torch.device(\"cpu\")\noutputs = model(images)\noutputs = [{k: v.to(cpu_device) for k, v in t.items()} for t in outputs]","metadata":{"execution":{"iopub.status.busy":"2022-07-06T18:26:09.412198Z","iopub.execute_input":"2022-07-06T18:26:09.412568Z","iopub.status.idle":"2022-07-06T18:26:09.965817Z","shell.execute_reply.started":"2022-07-06T18:26:09.412535Z","shell.execute_reply":"2022-07-06T18:26:09.964823Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"batch_of_images, batch_of_targets = next(iter(valid_data_loader))\n\nsample_boxes = batch_of_targets[0]['boxes'].numpy().astype(np.int32)\nsample_image = batch_of_images[0].permute(1,2,0).numpy() # convert back from pytorch format\n\nplt.imshow(bboxes_on_imgs(sample_image,sample_boxes,color=(0,200,200)))\n","metadata":{"execution":{"iopub.status.busy":"2022-07-06T18:50:02.856894Z","iopub.execute_input":"2022-07-06T18:50:02.857350Z","iopub.status.idle":"2022-07-06T18:50:06.963954Z","shell.execute_reply.started":"2022-07-06T18:50:02.857311Z","shell.execute_reply":"2022-07-06T18:50:06.962517Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"outputs","metadata":{"execution":{"iopub.status.busy":"2022-07-06T19:05:59.503603Z","iopub.execute_input":"2022-07-06T19:05:59.504565Z","iopub.status.idle":"2022-07-06T19:05:59.564075Z","shell.execute_reply.started":"2022-07-06T19:05:59.504526Z","shell.execute_reply":"2022-07-06T19:05:59.563093Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"images, targets = next(iter(valid_data_loader))\nimages, targets = move_batch_to_device(images, targets)\ncpu_device = torch.device(\"cpu\")\noutputs = model(images)\noutputs = [{k: v.to(cpu_device) for k, v in t.items()} for t in outputs]\noutputs","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for image, output, target in zip(images, outputs, targets): \n    print(output['scores'].cpu().detach().numpy())\n    print(output['boxes'].cpu().detach().numpy().astype(np.int32))\n    break","metadata":{"execution":{"iopub.status.busy":"2022-07-06T19:08:52.726658Z","iopub.execute_input":"2022-07-06T19:08:52.727045Z","iopub.status.idle":"2022-07-06T19:08:52.736195Z","shell.execute_reply.started":"2022-07-06T19:08:52.727012Z","shell.execute_reply":"2022-07-06T19:08:52.735027Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"# Prepare the model for inference\nmodel.eval()\n\n\n\n# Prepare a validation results generator\ndef make_validation_iter():\n    valid_data_iter = iter(valid_data_loader)\n    for images, targets in valid_data_iter:\n        images, targets = move_batch_to_device(images, targets)\n\n        cpu_device = torch.device(\"cpu\")\n        outputs = model(images)\n        outputs = [{k: v.to(cpu_device) for k, v in t.items()} for t in outputs]\n        for image, output, target in zip(images, outputs, targets): \n            scores = output['scores'].cpu().detach().numpy()\n            predicted_boxes = output['boxes'].cpu().detach().numpy().astype(np.int32)\n            ground_truth_boxes = target['boxes'].cpu().numpy().astype(np.int32)\n            s,p,g = scores,predicted_boxes,ground_truth_boxes\n            image = image.permute(1,2,0).cpu().numpy()\n            \n            \n            yield image, ground_truth_boxes, predicted_boxes,scores\n\nvalidation_iter = make_validation_iter()","metadata":{"execution":{"iopub.status.busy":"2022-07-06T19:22:43.302351Z","iopub.execute_input":"2022-07-06T19:22:43.303313Z","iopub.status.idle":"2022-07-06T19:22:43.314707Z","shell.execute_reply.started":"2022-07-06T19:22:43.303272Z","shell.execute_reply":"2022-07-06T19:22:43.313690Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# !pip install GPUtil\n\n# import torch\n# from GPUtil import showUtilization as gpu_usage\n# from numba import cuda\n\n# def free_gpu_cache():\n#     print(\"Initial GPU Usage\")\n#     gpu_usage()                             \n\n#     torch.cuda.empty_cache()\n\n#     cuda.select_device(0)\n#     cuda.close()\n#     cuda.select_device(0)\n\n#     print(\"GPU Usage after emptying the cache\")\n#     gpu_usage()\n\n# free_gpu_cache()                           ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cpu_device = torch.device(\"cpu\")\noutputs = model(images)\noutputs = [{k: v.to(cpu_device) for k, v in t.items()} for t in outputs]\nfor image, output, target in zip(images, outputs, targets): \n    scores = output['scores'].cpu().detach().numpy().astype(np.int32)\n    predicted_boxes = output['boxes'].cpu().detach().numpy().astype(np.int32)\n    ground_truth_boxes = target['boxes'].cpu().numpy().astype(np.int32)\n    image = image.permute(1,2,0).cpu().numpy()\n    break\nprint(scores)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#draw boxes on img\ndef bboxes_on_imgs_prob(image,boxes,scores,color=(255,0,0)):\n    for box,score in zip(boxes,scores):\n        cv2.rectangle(image,\n                      (int(box[0]),int(box[1])),\n                       (int(box[2]),int(box[3])),\n                       color,3)\n        cv2.putText(image, str(score), (int(box[0]),int(box[1])), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n    return image","metadata":{"execution":{"iopub.status.busy":"2022-07-06T19:22:48.598244Z","iopub.execute_input":"2022-07-06T19:22:48.599343Z","iopub.status.idle":"2022-07-06T19:22:48.607322Z","shell.execute_reply.started":"2022-07-06T19:22:48.599292Z","shell.execute_reply":"2022-07-06T19:22:48.606006Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"scores","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image, ground_truth_boxes, predicted_boxes,scores = next(validation_iter)\nimage = bboxes_on_imgs_prob(image,predicted_boxes,scores,(255,0,0))\nimage = bboxes_on_imgs_prob(image,ground_truth_boxes,scores,(0,255,0))\nplt.imshow(image)","metadata":{"execution":{"iopub.status.busy":"2022-07-06T19:22:50.913696Z","iopub.execute_input":"2022-07-06T19:22:50.914163Z","iopub.status.idle":"2022-07-06T19:22:55.995665Z","shell.execute_reply.started":"2022-07-06T19:22:50.914120Z","shell.execute_reply":"2022-07-06T19:22:55.994305Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}